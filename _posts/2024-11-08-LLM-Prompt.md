---
layout: post
title: LLM의 기본 개념과 Prompt 작성
subtitle: TIL Day 47
cover-img: "/assets/img/background.png"
thumbnail-img: ''
share-img: ''
tags: [TIL, LLM]
author: polaris0208
---
# INDEX

>[¶ LLM](#llm)
>- [¶ LLM 가본 개념](#llm-가본-개념)
>- [¶ RAG](#rag)
>- [¶ Vector DB](#vector-db)
>- [¶ LangChain](#langchain)
>
>[¶ Prompt 작성](#prompt-작성)
>- [¶ OpenAI Playground](#openai-playground)
>- [¶ Shot 기법](#shot-기법)
>- [¶ Act as 기법](#act-as-기법)
>- [¶ CoT 기법](#cot-기법)
>- [¶ 정보 제공 기법](#정보-제공-기법)
>- [¶ 형식 지정 기법](#형식-지정-기법)

# LLM

## LLM 가본 개념

### 개요
- **Large Language Model** 
- 다양한 언어 작업을 수행
- 방대한 텍스트 데이터를 학습
- 맥락을 통해 데이터를 조합

### 주요 기능
- **자연어 이해(NLU):** 질문이나 명령을 이해하고 적절히 응답
- **텍스트 생성:** 자연스러운 텍스트 생성
- **번역 및 요약:** 텍스트를 요약하거나 다른 언어로 번역
- **질문 응답 시스템(Q&A):** 정확한 답변 제공

## RAG

### 개요
- **Retrieval-Augmented Generation**
- **RAG**는 검색 기반 생성 기법
- **LLM**의 한계를 보완하기 위해 외부 데이터베이스에서 관련 정보를 검색하여 답변을 생성

### 동작 원리
1. **질문 입력:** 질문에 맞는 답변 생성 전 검색 단계 진행
2. **문서 검색:** 질문과 관련된 문서를 검색
3. **답변 생성:** 검색된 문서를 바탕으로 답변 생성

### 장점
- **최신 정보 활용**
- **특정 도메인 정보 제공**
- **효율성**

## Vector DB

### 개요
- 텍스트, 이미지 데이터를 벡터 형태로 변환해 저장
- 임베딩을 통해 데이터를 벡터화하여 유사성을 기반으로 검색

### 동작 과정
1. **Embedding 생성:** 텍스트를 벡터로 변환
2. **벡터 저장:** 데이터베이스에 저장
3. **벡터 검색:** 유사한 벡터를 검색
4. **결과 제공:** 유사한 벡터를 가진 데이터를 검색 결과로 제공

### 장점
- **의미 기반 검색**
- **고성능 처리**

## LangChain

### 개요
- **LLM**과 외부 리소스를 결합
- 다양한 애플리케이션을 효율적으로 개발할 수 있는 프레임워크

### 주요 기능
- **LLM과 데이터 소스 결합**
- **작업 흐름 자동화**
- **대화형 AI 개발**

### 동작 원리
1. **프롬프트 체인:** 여러 단계의 프롬프트를 연결.
2. **메모리 기능:** 대화의 맥락 유지.
3. **외부 리소스 통합:** API, 데이터베이스 등을 결합.

### LangChain의 장점
- **유연한 애플리케이션 개발**
- **확장성**
- **대화형 AI**

[¶ Top](#index)

# Prompt 작성

## OpenAI Playground

- **GPT** 모델을 실험할 수 있는 웹 기반의 환경으로
- 다양한 프롬프트를 입력하고 실시간으로 결과를 확인할 수 있는 플랫폼

### 주요 목적
- **프롬프트 테스트:** 입력 프롬프트에 따른 결과를 확인
- **모델 성능 평가:** 다양한 설정을 통해 모델의 성능을 평가
- **텍스트 생성 실험:** 실시간으로 텍스트를 생성하여 언어 모델의 동작 방식을 파악

### 주요 가능
1. **텍스트 생성:** 입력된 프롬프트를 바탕으로 GPT 모델이 답변을 생성
2. **다양한 작업 테스트:** 요약, 번역, 질문 답변, 창의적 글쓰기를 포함한 다양한 작업을 시험
3. **프롬프트 엔지니어링 실험:** 프롬프트의 작성 방식이나 내용에 따라 모델의 응답 변화를 실험

### 주요 설정

1. **모델 선택:** 
   - **GPT-4 family:** 복잡한 작업과 창의적 응답
   - **GPT-3.5 family:** 빠르고 효율적인 응답
2. **Temperature:** 
   - 값이 높을수록 창의적이고 예측 불가능한 응답.
   - 값이 낮을수록 일관적이고 안정적인 응답

3. **Max Tokens:** 생성할 텍스트 길이를 조절
4. **Top-p:** 응답 다양성을 제어

5. **Stop Sequences:** 특정 기호에서 응답 종료

### 주의점
- **Frequency Penalty:** 반복 방지를 위한 설정
- **Presence Penalty:** 다양한 표현을 유도하기 위한 설정

### 사용법
- 웹 브라우저에서 간단히 접근.
- 로그인 후, 모델과 설정을 선택하고 프롬프트를 입력하여 결과 확인.

### 실습 예시
1. **목표 설정:** 예: 글을 요약하는 모델
2. **프롬프트 작성:** 요약할 본문 입력
3. **파라미터 설정:** 모델과 다른 변수 조정
4. **결과 확인:** 모델이 생성한 요약 확인
5. **활용 팁:** 다양한 파라미터와 프롬프트 조합 시도

### 역할 설정
- **User:** 프롬프트 입력
- **Assistant:** 모델의 응답 생성
- **System:** 지침 제공

### 주의사항
1. **비용:** 사용한 토큰 수에 따라 비용 발생
2. **모델의 한계:** 항상 정확하지 않은 응답 가능성
3. **프라이버시와 보안:** 민감한 정보 입력 금지
4. **출력 조정:** 필요시 프롬프트 및 파라미터 수정

---

## Shot 기법

### Zero-Shot
- 예제를 주지 않고 지침만 전달함으로써 모델이 추론하도록 하는 기법

### One-Shot
- 예제를 하나 제공하여 모델의 추론을 유도

### Few-Shot
- 여러 예제를 제공하여 모델이 더 다양한 추론을 할 수 있도록 도와주는 기법

### Tip
- 과정을 예시로 제공하면 모델이 더 정확하게 추론

## Act As 기법
- 역할 ; **Persona** 부여
- 모델에게 특정 직업이나 역할을 부여하여 해당 직업이나 성격에 맞는 답변을 얻는 기법

### 역할 부여
- 변호사, 법률가, 상담가, 프로그래밍 강사 등 직업으로 설정하여 전문적인 답변 유도
- 성격, 취향, 배경 등을 설정한 가상인물로 부여하여 해당 성향의 답변 유도
- 번역기, 계산기, 프로그래밍 언어 등 역할을 부여하여 연산 결과 유도

---

## CoT 기법 
- **Chain of Thinking** 
- 논리적인 추론 과정을 단계별로 설명하도록 유도

### 자동화된 CoT 기법
- 모델에게 중간 과정을 설명해 달라고 요청함으로써, 문제 해결 과정을 상세히 풀이하도록 유도하는 기법

### 직접 중간 과정 넣어주기
- 중간 추론 단계를 직접 입력해 논리적 과정을 상세히 설명하도록 유도

---

## 정보 제공 기법

### System에 전달
- 정보를 한 번에 제공하며 모델이 이후에 그 정보를 잊지 않도록 보장

### Assistant에 전달
- 대화 중에 정보를 제공
- 기억할 수 있는 대화량에 한계가 있기 떄문에 한계가 있음

### 정리 
- 모델이 답변을 생성하는 데 부족한 추가 정보를 제공
  - **Prompt**에 작성하여 제공
  - 자료의 형태로 제공
  - 대화를 통해 정보 제공

---

## 형식 지정 기법
- 입력을 모델이 이해하기 쉬운 형태로 변형하여 전달

### Markdown
- `#` 헤더, `-` 리스트, `-, |` 등을 활용한 표 제공

### JSON
- 데이터를 키-값 쌍으로 표현하며, 데이터 처리 및 시스템 연동에 주로 사용

### Symbol
- 중요한 부분을 강조하기 위해 사용
- `**강조**`등을 이용하여 중요한 부분 강조

[¶ Top](#index)